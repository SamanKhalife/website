---
title: چند مستاجری
content_type: concept
weight: 80
---

<!-- overview -->

این صفحه مروری بر گزینه‌های پیکربندی موجود و بهترین روش‌ها برای چند مستاجری در کلاستر ارائه می‌دهد.

اشتراک‌گذاری کلاسترها هزینه‌ها را کاهش می‌دهد و مدیریت را ساده‌تر می‌کند. با این حال، اشتراک‌گذاری کلاسترها چالش‌هایی مانند امنیت، انصاف و مدیریت _همسایگان پرسروصدا_ را نیز به همراه دارد.

کلاسترها می‌توانند به روش‌های مختلفی به اشتراک گذاشته شوند. در برخی موارد، برنامه‌های مختلف ممکن است در یک کلاستر اجرا شوند. در موارد دیگر، چندین نمونه از یک برنامه می‌توانند در یک کلاستر اجرا شوند، هر کدام برای یک کاربر نهایی. تمامی این نوع اشتراک‌ها اغلب با اصطلاح چتر _چند مستاجری_ توصیف می‌شوند.

در حالی که Kubernetes مفاهیم اصلی کاربران نهایی یا مستاجران را ندارد، چندین ویژگی برای کمک به مدیریت نیازهای مختلف چند مستاجری فراهم می‌کند. این ویژگی‌ها در ادامه مورد بحث قرار می‌گیرند.

<!-- body -->
## موارد استفاده

اولین قدم برای تعیین نحوه اشتراک‌گذاری کلاستر شما، درک مورد استفاده شماست تا بتوانید الگوها و ابزارهای موجود را ارزیابی کنید. به طور کلی، چند مستاجری در کلاسترهای Kubernetes به دو دسته کلی تقسیم می‌شود، اگرچه بسیاری از تغییرات و ترکیب‌ها نیز ممکن است.

### تیم‌های متعدد

یک فرم رایج از چند مستاجری اشتراک یک کلاستر بین چند تیم در یک سازمان است، که هر کدام ممکن است یک یا چند بار کاری را اجرا کنند. این بارهای کاری اغلب نیاز به ارتباط با یکدیگر و با بارهای کاری دیگر در همان یا کلاسترهای مختلف دارند.

در این سناریو، اعضای تیم‌ها اغلب دسترسی مستقیم به منابع Kubernetes از طریق ابزارهایی مانند `kubectl` دارند، یا دسترسی غیرمستقیم از طریق کنترلرهای GitOps یا انواع دیگر ابزارهای اتوماسیون انتشار دارند. معمولاً سطحی از اعتماد بین اعضای تیم‌های مختلف وجود دارد، اما سیاست‌های Kubernetes مانند RBAC، سهمیه‌ها و سیاست‌های شبکه برای اشتراک‌گذاری امن و منصفانه کلاسترها ضروری هستند.

### مشتریان متعدد

نوع دیگر رایج از چند مستاجری اغلب شامل یک فروشنده نرم‌افزار به عنوان سرویس (SaaS) است که چندین نمونه از یک بار کاری را برای مشتریان اجرا می‌کند. این مدل کسب و کار با این سبک استقرار آنقدر مرتبط است که بسیاری از افراد آن را "چند مستاجری SaaS" می‌نامند. با این حال، یک اصطلاح بهتر ممکن است "چند مستاجری مشتریان متعدد" باشد، زیرا فروشندگان SaaS ممکن است از مدل‌های استقرار دیگر نیز استفاده کنند و این مدل استقرار نیز می‌تواند خارج از SaaS استفاده شود.

در این سناریو، مشتریان دسترسی به کلاستر ندارند؛ Kubernetes از دیدگاه آنها نامرئی است و فقط توسط فروشنده برای مدیریت بارهای کاری استفاده می‌شود. بهینه‌سازی هزینه‌ها اغلب یک نگرانی حیاتی است و سیاست‌های Kubernetes برای اطمینان از اینکه بارهای کاری به شدت از یکدیگر جدا هستند، استفاده می‌شود.

## اصطلاحات

### مستاجران

هنگام بحث در مورد چند مستاجری در Kubernetes، هیچ تعریف واحدی برای "مستاجر" وجود ندارد. بلکه، تعریف یک مستاجر بسته به اینکه آیا چند مستاجری تیمی یا چند مستاجری مشتریان متعدد مورد بحث قرار می‌گیرد، متفاوت خواهد بود.

در استفاده تیمی، یک مستاجر معمولاً یک تیم است، که هر تیم معمولاً تعداد کمی بار کاری را که با پیچیدگی سرویس مقیاس می‌شود، مستقر می‌کند. با این حال، تعریف "تیم" ممکن است خود مبهم باشد، زیرا تیم‌ها ممکن است به واحدهای بالاتر سازماندهی شوند یا به تیم‌های کوچکتر تقسیم شوند.

در مقابل، اگر هر تیم بارهای کاری اختصاصی برای هر مشتری جدید مستقر کند، آنها از یک مدل چند مستاجری مشتریان متعدد استفاده می‌کنند. در این حالت، "مستاجر" به سادگی گروهی از کاربران است که یک بار کاری را به اشتراک می‌گذارند. این گروه ممکن است به اندازه یک شرکت کامل یا به کوچکی یک تیم در آن شرکت باشد.

در بسیاری از موارد، همان سازمان ممکن است هر دو تعریف از "مستاجران" را در زمینه‌های مختلف استفاده کند. به عنوان مثال، یک تیم پلتفرم ممکن است سرویس‌های مشترکی مانند ابزارهای امنیتی و پایگاه‌های داده را به چندین "مشتری" داخلی ارائه دهد و یک فروشنده SaaS ممکن است چندین تیم داشته باشد که یک کلاستر توسعه را به اشتراک می‌گذارند. در نهایت، معماری‌های ترکیبی نیز ممکن است وجود داشته باشند، مانند یک ارائه‌دهنده SaaS که از ترکیبی از بارهای کاری اختصاصی برای داده‌های حساس و سرویس‌های مشترک چند مستاجری استفاده می‌کند.

{{< figure src="/images/docs/multi-tenancy.png" title="یک کلاستر که مدل‌های چند مستاجری همزیستی را نشان می‌دهد" class="diagram-large" >}}

### ایزوله‌سازی

چندین روش برای طراحی و ساخت راه‌حل‌های چند مستاجری با Kubernetes وجود دارد. هر یک از این روش‌ها مجموعه‌ای از مبادلات خود را دارند که بر سطح ایزوله‌سازی، تلاش برای پیاده‌سازی، پیچیدگی عملیاتی و هزینه سرویس تأثیر می‌گذارند.

یک کلاستر Kubernetes شامل یک صفحه کنترل که نرم‌افزار Kubernetes را اجرا می‌کند و یک صفحه داده که از نودهای کارگری تشکیل شده است که بارهای کاری مستاجران به صورت پاد در آنها اجرا می‌شوند. ایزوله‌سازی مستاجران می‌تواند هم در صفحه کنترل و هم در صفحه داده بر اساس نیازهای سازمانی اعمال شود.

سطح ایزوله‌سازی ارائه شده گاهی با اصطلاحاتی مانند "چند مستاجری سخت" که به معنای ایزوله‌سازی قوی است و "چند مستاجری نرم" که به معنای ایزوله‌سازی ضعیف‌تر است، توصیف می‌شود. به ویژه، "چند مستاجری سخت" اغلب برای مواردی استفاده می‌شود که مستاجران به یکدیگر اعتماد ندارند، معمولاً از دیدگاه امنیتی و اشتراک منابع (مانند محافظت در برابر حملاتی مانند استخراج داده یا DoS). از آنجا که صفحات داده معمولاً سطح حمله بسیار بزرگی دارند، "چند مستاجری سخت" اغلب نیاز به توجه ویژه به ایزوله‌سازی صفحه داده دارد، هرچند ایزوله‌سازی صفحه کنترل نیز همچنان حیاتی است.

با این حال، اصطلاحات "سخت" و "نرم" می‌توانند اغلب گیج‌کننده باشند، زیرا هیچ تعریف واحدی وجود ندارد که برای همه کاربران قابل اعمال باشد. بلکه، "سختی" یا "نرمی" بهتر است به عنوان یک طیف گسترده درک شود، با تکنیک‌های مختلفی که می‌توانند برای حفظ انواع مختلف ایزوله‌سازی در کلاسترهای شما بر اساس نیازهای شما استفاده شوند.

در موارد شدیدتر، ممکن است آسان‌تر یا ضروری باشد که از هرگونه اشتراک‌گذاری در سطح کلاستر صرف‌نظر کنید و هر مستاجر را به کلاستر اختصاصی خود اختصاص دهید، حتی ممکن است روی سخت‌افزار اختصاصی اجرا شود اگر ماشین‌های مجازی به عنوان یک مرز امنیتی کافی در نظر گرفته نشوند. این ممکن است با کلاسترهای مدیریت‌شده Kubernetes آسان‌تر باشد، جایی که اضافه‌بار ایجاد و مدیریت کلاسترها حداقل تا حدی توسط یک ارائه‌دهنده ابری به عهده گرفته می‌شود. مزیت ایزوله‌سازی قوی‌تر مستاجران باید در مقابل هزینه و پیچیدگی مدیریت چندین کلاستر ارزیابی شود. [Multi-cluster SIG](https://git.k8s.io/community/sig-multicluster/README.md) مسئول رسیدگی به این نوع موارد استفاده است.

باقی‌مانده این صفحه بر تکنیک‌های ایزوله‌سازی برای کلاسترهای Kubernetes مشترک تمرکز دارد. با این حال، حتی اگر به کلاسترهای اختصاصی فکر می‌کنید، ممکن است مرور این توصیه‌ها ارزشمند باشد، زیرا به شما انعطاف‌پذیری برای تغییر به کلاسترهای مشترک در آینده را می‌دهد اگر نیازها یا قابلیت‌های شما تغییر کند.
## ایزوله‌سازی صفحه کنترل

ایزوله‌سازی صفحه کنترل تضمین می‌کند که مستاجران مختلف نمی‌توانند به منابع API Kubernetes یکدیگر دسترسی پیدا کنند یا آنها را تحت تأثیر قرار دهند.

### نام‌فضاها

در Kubernetes، یک {{< glossary_tooltip text="Namespace" term_id="namespace" >}} مکانیزمی برای ایزوله‌سازی گروه‌هایی از منابع API در یک کلاستر فراهم می‌کند. این ایزوله‌سازی دارای دو بعد کلیدی است:

1. نام اشیا درون یک نام‌فضا می‌تواند با نام‌ها در نام‌فضاهای دیگر تداخل داشته باشد، مشابه فایل‌ها در پوشه‌ها. این اجازه می‌دهد تا مستاجران منابع خود را نام‌گذاری کنند بدون اینکه نیاز باشد به فعالیت مستاجران دیگر توجه کنند.

2. بسیاری از سیاست‌های امنیتی Kubernetes در محدوده نام‌فضاها هستند. به عنوان مثال، نقش‌های RBAC و سیاست‌های شبکه منابع محدوده‌دار هستند. با استفاده از RBAC، کاربران و حساب‌های سرویس می‌توانند به یک نام‌فضا محدود شوند.

در یک محیط چند مستاجری، یک نام‌فضا به تفکیک بار کاری یک مستاجر به یک واحد مدیریت منطقی و متمایز کمک می‌کند. در واقع، یک رویه معمول این است که هر بار کاری را در نام‌فضای خود ایزوله کنید، حتی اگر چندین بار کاری توسط یک مستاجر انجام شود. این اطمینان می‌دهد که هر بار کاری هویت خود را دارد و می‌تواند با یک سیاست امنیتی مناسب پیکربندی شود.

مدل ایزوله‌سازی نام‌فضا نیاز به پیکربندی چندین منبع دیگر Kubernetes، افزونه‌های شبکه و پایبندی به بهترین روش‌های امنیتی برای ایزوله‌سازی صحیح بارهای کاری مستاجران دارد. این ملاحظات در ادامه بحث شده‌اند.

### کنترل‌های دسترسی

مهمترین نوع ایزوله‌سازی برای صفحه کنترل، مجوزدهی است. اگر تیم‌ها یا بارهای کاری آنها بتوانند به منابع API یکدیگر دسترسی پیدا کنند یا آنها را تغییر دهند، می‌توانند تمامی انواع سیاست‌های دیگر را تغییر دهند یا غیرفعال کنند و بدین ترتیب هر گونه حفاظتی که این سیاست‌ها ممکن است ارائه دهند را نفی کنند. در نتیجه، اطمینان از اینکه هر مستاجر فقط به نام‌فضاهای مورد نیاز خود دسترسی دارد و نه بیشتر، حیاتی است. این به عنوان "اصل کمترین امتیاز" شناخته می‌شود.

کنترل دسترسی مبتنی بر نقش (RBAC) معمولاً برای اعمال مجوزدهی در صفحه کنترل Kubernetes استفاده می‌شود، هم برای کاربران و هم برای بارهای کاری (حساب‌های سرویس).
[نقش‌ها](/docs/reference/access-authn-authz/rbac/#role-and-clusterrole) و
[پیوندهای نقش](/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding) اشیای Kubernetes هستند که در سطح نام‌فضا برای اعمال کنترل دسترسی در برنامه شما استفاده می‌شوند؛ اشیای مشابهی برای مجوزدهی دسترسی به اشیای سطح کلاستر وجود دارد، اگرچه اینها کمتر برای کلاسترهای چند مستاجری مفید هستند.

در یک محیط چند تیمی، RBAC باید برای محدود کردن دسترسی مستاجران به نام‌فضاهای مناسب و اطمینان از اینکه منابع در سطح کلاستر فقط توسط کاربران مجاز مانند مدیران کلاستر قابل دسترسی یا تغییر هستند، استفاده شود.

اگر یک سیاست به یک کاربر بیش از نیازش مجوز بدهد، این احتمالاً نشانه‌ای است که نام‌فضای حاوی منابع مورد نظر باید به نام‌فضاهای ریزدانه‌تر بازسازی شود. ابزارهای مدیریت نام‌فضا ممکن است مدیریت این نام‌فضاهای ریزدانه‌تر را با اعمال سیاست‌های RBAC مشترک به نام‌فضاهای مختلف ساده‌تر کنند، در حالی که همچنان اجازه سیاست‌های ریزدانه‌تر را در مواقع ضروری می‌دهند.

### سهمیه‌ها

بارهای کاری Kubernetes منابع نود مانند CPU و حافظه را مصرف می‌کنند. در یک محیط چند مستاجری، می‌توانید از [سهمیه‌های منابع](/docs/concepts/policy/resource-quotas/) برای مدیریت استفاده منابع بارهای کاری مستاجران استفاده کنید. برای مورد استفاده چند تیمی، جایی که مستاجران به API Kubernetes دسترسی دارند، می‌توانید از سهمیه‌های منابع برای محدود کردن تعداد منابع API (برای مثال: تعداد پادها یا تعداد ConfigMapها) که یک مستاجر می‌تواند ایجاد کند، استفاده کنید. محدودیت‌ها بر روی تعداد اشیا اطمینان از انصاف و جلوگیری از تأثیرات _همسایگان پرسروصدا_ بر سایر مستاجران که صفحه کنترل را به اشتراک می‌گذارند، دارند.

سهمیه‌های منابع اشیای نام‌فضا دار هستند. با نگاشت مستاجران به نام‌فضاها، مدیران کلاستر می‌توانند از سهمیه‌ها برای اطمینان از اینکه یک مستاجر نمی‌تواند منابع کلاستر را انحصاری کند یا صفحه کنترل آن را بیش از حد بارگذاری کند، استفاده کنند. ابزارهای مدیریت نام‌فضا مدیریت سهمیه‌ها را ساده می‌کنند. علاوه بر این، در حالی که سهمیه‌های Kubernetes فقط در یک نام‌فضا اعمال می‌شوند، برخی ابزارهای مدیریت نام‌فضا اجازه می‌دهند گروه‌هایی از نام‌فضاها سهمیه‌ها را به اشتراک بگذارند، که به مدیران انعطاف‌پذیری بسیار بیشتری با تلاش کمتر نسبت به سهمیه‌های داخلی می‌دهد.

سهمیه‌ها از مصرف بیشتر از سهمیه تخصیص یافته توسط یک مستاجر جلوگیری می‌کنند و در نتیجه مسئله "همسایگان پرسروصدا" را که یک مستاجر عملکرد بارهای کاری سایر مستاجران را منفی تحت تأثیر قرار می‌دهد، به حداقل می‌رسانند.

هنگام اعمال یک سهمیه به نام‌فضا، Kubernetes نیاز دارد که همچنین درخواست‌ها و محدودیت‌های منابع را برای هر کانتینر مشخص کنید. محدودیت‌ها حد بالای مقدار منابعی هستند که یک کانتینر می‌تواند مصرف کند. کانتینرهایی که سعی می‌کنند منابعی بیشتر از محدودیت‌های تنظیم شده مصرف کنند، بر اساس نوع منبع یا کاهش داده می‌شوند یا کشته می‌شوند. هنگامی که درخواست‌های منابع کمتر از محدودیت‌ها تنظیم شده‌اند، هر کانتینر مقدار درخواست شده را تضمین می‌کند اما ممکن است هنوز هم پتانسیلی برای تأثیرگذاری بر روی بارهای کاری وجود داشته باشد.

سهمیه‌ها نمی‌توانند از همه انواع اشتراک منابع مانند ترافیک شبکه محافظت کنند. ایزوله‌سازی نود (که در زیر توضیح داده شده است) ممکن است راه حل بهتری برای این مشکل باشد.

## ایزوله‌سازی صفحه داده

ایزوله‌سازی صفحه داده تضمین می‌کند که پادها و بارهای کاری مستاجران مختلف به اندازه کافی ایزوله شده‌اند.

### ایزوله‌سازی شبکه

به طور پیش‌فرض، همه پادها در یک کلاستر Kubernetes اجازه دارند با یکدیگر ارتباط برقرار کنند و همه ترافیک شبکه رمزگذاری نشده است. این می‌تواند به آسیب‌پذیری‌های امنیتی منجر شود که در آن ترافیک به طور تصادفی یا مخرب به مقصد ناخواسته ارسال می‌شود یا توسط بار کاری روی یک نود خراب‌کاری شده رهگیری می‌شود.

ارتباط پاد به پاد می‌تواند با استفاده از [سیاست‌های شبکه](/docs/concepts/services-networking/network-policies/) کنترل شود که ارتباط بین پادها را با استفاده از برچسب‌های نام‌فضا یا محدوده‌های آدرس IP محدود می‌کند. در یک محیط چند مستاجری که ایزوله‌سازی شبکه سخت بین مستاجران مورد نیاز است، شروع با یک سیاست پیش‌فرض که ارتباط بین پادها را ممنوع می‌کند و یک قانون دیگر که به همه پادها اجازه می‌دهد سرور DNS را برای نام‌گذاری پرس‌وجو کنند، توصیه می‌شود. با چنین سیاست پیش‌فرضی در جای خود، می‌توانید شروع به افزودن قوانین مجازتر کنید که ارتباط درون یک نام‌فضا را امکان‌پذیر می‌سازد. همچنین توصیه می‌شود که از انتخاب‌گر برچسب خالی '{}' برای فیلد namespaceSelector در تعریف سیاست شبکه استفاده نکنید، در صورتی که نیاز به اجازه ترافیک بین نام‌فضاها وجود داشته باشد. این طرح می‌تواند به عنوان نیاز اصلاح شود. توجه داشته باشید که این فقط برای پادها درون یک صفحه کنترل اعمال می‌شود؛ پادهایی که به صفحه‌های کنترل مجازی مختلف تعلق دارند نمی‌توانند از طریق شبکه Kubernetes با یکدیگر صحبت کنند.

ابزارهای مدیریت نام‌فضا ممکن است ایجاد سیاست‌های شبکه پیش‌فرض یا مشترک را ساده‌تر کنند. علاوه بر این، برخی از این ابزارها اجازه می‌دهند که مجموعه‌ای ثابت از برچسب‌های نام‌فضا در سراسر کلاستر شما اعمال شود، اطمینان حاصل می‌کند که آنها مبنای معتبری برای سیاست‌های شما هستند.

{{< warning >}}
سیاست‌های شبکه نیاز به یک [افزونه CNI](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni) دارند که از پیاده‌سازی سیاست‌های شبکه پشتیبانی کند. در غیر این صورت، منابع
### جداسازی ذخیره‌سازی

کوبرنیتیز انواع مختلفی از حجم‌ها را که می‌توانند برای ذخیره‌سازی مداوم بارها استفاده شوند ارائه می‌دهد. برای امنیت و جداسازی داده، [تامین حجم پویا](/docs/concepts/storage/dynamic-provisioning/) توصیه می‌شود و از انواع حجم‌هایی که از منابع گره استفاده می‌کنند باید پرهیز شود.

[کلاس‌های ذخیره‌سازی](/docs/concepts/storage/storage-classes/) به شما اجازه می‌دهند که کلاس‌های "سفارشی" از ذخیره‌سازی ارائه شده توسط خوشه خود را بر اساس سطوح کیفیت خدمات، سیاست‌های پشتیبانی یا سیاست‌های سفارشی که توسط مدیران خوشه تعیین شده‌اند، توصیف کنید.

پادها می‌توانند درخواست ذخیره‌سازی را با استفاده از [دعوت‌نامه حجم‌های مداوم](/docs/concepts/storage/persistent-volumes/) درخواست کنند. یک دعوت‌نامه حجم مداوم یک منبع namespace دار است که امکان جداسازی بخش‌های سیستم ذخیره‌سازی را فراهم می‌کند و آن را به مستاجران داخل خوشه مشترک اختصاص می‌دهد.
همچنین باید توجه داشت که یک حجم مداوم یک منبع در سطح کلوستر است و یک چرخه مستقل از بارها و فضاها دارد.

به عنوان مثال، می‌توانید برای هر مستاجر یک کلاس ذخیره‌سازی جداگانه پیکربندی کنید و از آن برای تقویت جداسازی استفاده کنید. اگر یک کلاس ذخیره‌سازی به اشتراک گذاشته شود، باید یک [سیاست بازیابی `Delete`](/docs/concepts/storage/storage-classes/#reclaim-policy) را تنظیم کنید تا اطمینان حاصل شود که یک حجم مداوم نمی‌تواند در سراسر فضاهای نامهای مختلف دوباره استفاده شود.

### عایق‌زدن مخازن

{{% thirdparty-content %}}

پادهای کوبرنیتیز از یک یا چندین کانتینر تشکیل شده‌اند که در گره‌های کارگر اجرا می‌شوند.
کانتینرها از مجازی‌سازی سطح سیستم عامل استفاده می‌کنند و به همین دلیل مرز جداسازی آن‌ها ضعیف‌تر از ماشین‌های مجازی است که از مجازی‌سازی مبتنی بر سخت‌افزار استفاده می‌کنند.

در یک محیط به اشتراک گذاشته شده، آسیب‌پذیری‌های غیرترمیم‌شده در لایه‌های برنامه و سیستم می‌توانند توسط حملات‌کنندگان برای خروج از کانتینر و اجرای کد یا اسکریپت‌های ناامن که اجازه دسترسی به منابع میزبان را می‌دهند، بهره‌برداری شوند. در برخی برنامه‌ها، مانند یک سیستم مدیریت محتوا (CMS)، به مشتریان ممکن است اجازه داده شود که اسکریپت‌ها یا کد‌های ناامن را بارگذاری و اجرا کنند. در هر دو مورد، مکانیسم‌هایی برای عایق‌زدن و حفاظت از بارها با استفاده از جداسازی قوی مطلوب است.

عایق‌زدن یک راه برای جداسازی بارهای کاری در حال اجرا در یک خوشه به اشتراک گذاشته شده است. اغلب این به اجرای هر پاد در یک محیط اجرایی جداگانه مانند یک ماشین مجازی یا یک هسته فضای کاربری مربوط می‌شود. عایق‌زدن اغلب زمانی توصیه می‌شود که کد ناامن را اجرا می‌کنید، جایی که بارهای کاری فرض می‌شود خبیث باشند. بخشی از دلیل این نوع جداسازی این است که کانتینرها فرایندهایی هستند که در یک هسته مشترک اجرا می‌شوند؛ آن‌ها از فضاهای فایل مانند `/sys` و `/proc` از میزبان زیرین بارگذاری می‌کنند، که آن‌ها را کمتر از یک برنامه که روی یک ماشین مجازی اجرا می‌شود و دارای هسته‌ای خود است، امن می‌کند. در حالی که کنترل‌هایی مانند seccomp، AppArmor و SELinux برای تقویت امنیت کانتینرها می‌توانند استفاده شوند، این سخت است که یک مجموعه یکانی از قوانین را به همه بارهای در حال اجرا در یک خوشه به اشتراک گذاشته شده اعمال کرد. اجرای بارها در یک محیط عایق‌زده کمک می‌کند که از فرار کانتینر جلوگیری شود، جایی که حمله‌کننده آسیب‌پذیری را ب

رای دسترسی به سیستم میزبان و تمام فرایندها/فایل‌های در حال اجرا در آن میزبان بهره‌مند می‌شود.

ماشین‌های مجازی و هسته‌های فضای کاربری دو رویکرد محبوب برای عایق‌زدن هستند. پیاده‌سازی‌های عایق‌زدن زیر در دسترس هستند:

- [gVisor](https://gvisor.dev/): سیستم‌عامل بستر را از طریق کرنل فضای کاربری اجرا می‌کند که با دسترسی محدود به میزبان زیرین، نوشته شده است.
- [Kata Containers](https://katacontainers.io/): یک زمان اجرای کانتینر امن ارائه می‌دهد که به شما امکان می‌دهد تا کانتینرها را در یک ماشین مجازی اجرا کنید. مجازی‌سازی سخت‌افزاری موجود در Kata امنیت اضافی برای کانتینرهایی که کد ناامن را اجرا می‌کنند، ارائه می‌دهد.

### جداسازی گره

جداسازی گره یک تکنیک دیگر است که می‌توانید برای جداسازی بارهای کاری مستاجران از هم استفاده کنید. با جداسازی گره، یک مجموعه از گره‌ها به اجرای پادهای یک مستاجر خاص اختصاص داده شده‌اند و مخلوط کردن پادهای مستاجر ممنوع است. این پیکربندی مشکل صدای مستاجر را کاهش می‌دهد، زیرا همه پادهایی که بر روی یک گره اجرا می‌شوند، به یک تنه مستاجر تعلق دارند. خطر افشای اطلاعات با جداسازی گره کمی کمتر است، زیرا یک حمله‌کننده که موفق به فرار از یک کانتینر شود فقط به دسترس برخی از کانتینرها و حجم‌های نصب شده بر روی آن گره خواهد بود.

هرچند که بارهای کاری از مستاجران مختلف بر روی گره‌های مختلف در حال اجرا هستند، مهم است که آن‌ها بدانند که kubelet و (مگر اینکه از سکوهای کنترل مجازی استفاده می‌کنند) سرویس API همچنان خدمات به اشتراک گذاشته شده هستند. یک حمله‌کننده ماهر ممکن است از اجازه‌های اختصاص داده شده به kubelet یا دیگر پادهای در حال اجرا بر روی گره استفاده کند تا به صورت افقی در داخل خوشه حرکت کند و دسترسی به بارهای کاری مستاجران در حال اجرا بر روی دیگر گره‌ها را به دست آورد. اگر این یک نگرانی اساسی است، در نظر بگیرید که کنترل‌های جبرانی مانند seccomp، AppArmor یا SELinux را اجرا کنید یا از عایق‌زدن کانتینرها استفاده کنید یا خوشه‌های جداگانه برای هر مستاجر ایجاد کنید.

جداسازی گره از نظر محاسبه هزینه نسبت به عایق‌زدن کانتینرها آسان‌تر است، زیرا می‌توانید هر گره را بر اساس تعداد تن‌ها برگشت دهید تا پادهای مشخص با مشخصات خاصیت همگون شوند و از نظر سازگاری و عملکرد مسائل کمتری دارد و ممکن است آسان‌تر از عایق‌زدن کانتینرها پیاده‌سازی شود. به عنوان مثال، می‌توان به هر مستاجر گره‌ها با تن‌های خاص توسط گره‌ها آن‌ها پیکربندی کرد، تا فقط پادهای با تحمل مربوطه بر روی آن‌ها اجرا شوند. یک webhook تغییری ممکن است به طور خودکار تحملات و تناسب‌های گره به پادهایی که در فضای‌نامهای مستاجر منتشر می‌شوند اضافه کند، تا بر روی یک مجموعه خاص از گره‌ها که برای آن مستاجر تعیین شده است، اجرا شوند.

می‌توان با استفاده از [انتخاب‌گره پاد](/docs/concepts/scheduling-eviction/assign-pod-node/) یا [Kubelet مجازی](https://github.com/virtual-kubelet) عایق‌زدن گره را پیاده‌سازی کرد.

## ملاحظات اضافی

در این بخش، ساختارها و الگوهای دیگر کوبرنیتیز که برای چندمستاجری مرتبط هستند، مورد بحث قرار می‌گیرد.

### اولویت API و عدالت

[اولویت API و عدالت](/docs/concepts/cluster-administration/flow-control/) یک ویژگی کوبرنیتیز است که به شما امکان می‌دهد اولویتی را به برخی از پادهای در حال اجرا در خوشه اختصاص دهید. زمانی که یک برنامه از API کوبرنیتیز فراخوانی می‌شود، سرور API اولویت اختصاص داده شده به پاد را ارزیابی می‌کند. تماس‌ها از پادهای با اولویت بالاتر

 پیش از آن‌های با اولویت پایین‌تر پاسخ داده می‌شود. زمانی که رقابت زیاد است، تماس‌های با اولویت پایین‌تر ممکن است تا زمانی که سرور کمتر شلوغ باشد در صف قرار گیرند یا می‌توانید درخواست‌ها را رد کنید.

استفاده از اولویت API و عدالت در محیط‌های SaaS به ندرت استفاده می‌شود مگر اینکه به مشتریان اجازه دهید که برنامه‌هایی را اجرا کنند که با API کوبرنیتیز ارتباط برقرار می‌کنند، به عنوان مثال کنترل کننده‌ای.

### کیفیت خدمات (QoS) {#qos}

وقتی یک برنامه SaaS اجرا می‌کنید، ممکن است بخواهید توانایی ارائه لایه‌های مختلف کیفیت خدمات (QoS) را به مستاجران مختلف ارائه دهید. به عنوان مثال، ممکن است داشته باشید که سرویس فریمیوم که با تضمین‌های عملکرد و ویژگی‌های کمتری همراه است و یک لایه سرویس اختیاری که با تضمین‌های عملکرد و ویژگی‌های خاص مشخص شده است. خوشبختانه، چندین ساختار کوبرنیتی وجود دارد که می‌تواند به شما کمک کند تا این کار را در یک خوشه به اشتراک گذاشته انجام دهید، از جمله QoS شبکه، کلاس‌های ذخیره سازی و اولویت و پیش‌برنامه پاد. ایده با هر یک از اینها این است که به مستاجران امکان دهید کیفیت خدماتی که پرداخت کرده‌اند را ارائه دهید. بیایید با نگاهی به QoS شبکه شروع کنیم.

معمولاً همه پادها در یک گره، یک رابط شبکه را به اشتراک می‌گذارند. بدون QoS شبکه، برخی از پادها ممکن است به سهم نامنصفی از پهنای باند موجود برای هزینه‌هایی دیگر از پادها مصرف کنند. پلاگین پهنای باند Kubernetes یک [منبع گسترده](/docs/concepts/configuration/manage-resources-containers/#extended-resources) برای شبکه ایجاد می‌کند که به شما امکان می‌دهد از ساختارهای منابع Kubernetes، یعنی درخواست‌ها/محدودیت‌ها، برای اعمال محدودیت‌های نرخ به پادها با استفاده از صفوف Linux tc استفاده کنید. به یاد داشته باشید که این پلاگین به عنوان آزمایشی در نظر گرفته شده است طبق مستندات [افزونه‌های شبکه](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping) و قبل از استفاده در محیط‌های تولیدی باید به طور جدی تست شود.

برای QoS ذخیره سازی، احتمالاً می‌خواهید کلاس‌های ذخیره سازی یا پروفایل‌های مختلف با خصوصیات عملکرد متفاوت ایجاد کنید. هر پروفایل ذخیره‌سازی می‌تواند با یک لایه خدماتی متفاوت که برای بارهای کاری مختلف بهینه شده است، مرتبط شود مانند IO، تکرار یا پهنای باند. منطق اضافی ممکن است لازم باشد تا به مستاجر اجازه دهید که پروفایل ذخیره سازی مناسب را با بار کاری خود مرتبط کنند.

و در نهایت، اولویت پاد و پیش‌برنامه‌سازی را می‌توان [اولویت پاد و پیش‌برنامه‌سازی](/docs/concepts/scheduling-eviction/pod-priority-preemption/) که به شما امکان می‌دهد ارزش‌های اولویتی را به پادها اختصاص دهید. هنگام برنامه‌ریزی پادها، برنامه‌ریز سعی می‌کند پادهای با اولویت پایین‌تر را تخلیه کند زمانی که منابع کافی برای برنامه‌ریزی پادهایی که به اولویت بالاتر اختصاص داده شده‌اند، وجود ندارد. اگر یک مورد استفاده دارید که مستاجران دارای طبقات خدماتی مختلف در یک خوشه به اشتراک گذاشته شده دارید مثلاً رایگان و پرداخت، ممکن است بخواهید با استفاده از این ویژگی به طبقات خاصی اولویت بیشتری دهید.
### DNS

در خوشه‌های Kubernetes، یک سرویس سامانه نام‌گذاری (DNS) وجود دارد که برای ارائه ترجمه‌ها از نام‌ها به آدرس‌های IP برای همه خدمات و پادها استفاده می‌شود. به طور پیش‌فرض، سرویس DNS Kubernetes امکان پیدا کردن نام‌ها در تمام فضاهای نام در خوشه را فراهم می‌کند.

در محیط‌های چند‌مستاجره که مستاجران می‌توانند به پادها و منابع Kubernetes دیگر دسترسی پیدا کنند، یا در جاهایی که نیاز به جداسازی قوی‌تر وجود دارد، ممکن است لازم باشد جلوگیری از پادها برای جستجوی خدمات در فضاهای نام دیگر را فعال کرد.

شما می‌توانید با پیکربندی قوانین امنیتی برای سرویس DNS، جستجوی DNS عبور-فضاهای نام را محدود کنید. به عنوان مثال، CoreDNS (سرویس DNS پیش‌فرض برای Kubernetes) می‌تواند با استفاده از متادیتای Kubernetes، پرس‌وجوها را به پادها و خدمات در یک فضای نام محدود کند. برای اطلاعات بیشتر، یک [مثال](https://github.com/coredns/policy#kubernetes-metadata-multi-tenancy-policy) از پیکربندی این ویژگی در مستندات CoreDNS را بخوانید.

وقتی که از مدل [کنترل پلیر مجازی برای هر مستاجر](#virtual-control-plane-per-tenant) استفاده می‌شود، لازم است یک سرویس DNS برای هر مستاجر پیکربندی شود یا از یک سرویس DNS چند‌مستاجره استفاده شود. برای مثال، یک [نسخه سفارشی از CoreDNS](https://github.com/kubernetes-sigs/cluster-api-provider-nested/blob/main/virtualcluster/doc/tenant-dns.md) که از چندین مستاجر پشتیبانی می‌کند را می‌توانید ببینید.

### اپراتورها

[اپراتورها](/docs/concepts/extend-kubernetes/operator/) کنترل‌کننده‌های Kubernetes هستند که برنامه‌ها را مدیریت می‌کنند. اپراتورها می‌توانند مدیریت چندین نمونه از یک برنامه مانند یک خدمت پایگاه داده را ساده‌تر کنند که آن‌ها را به عنوان یک قطعه ساختمانی مشترک در مورد استفاده از چند مصرف‌کننده (SaaS) چند‌مستاجره.

اپراتورهای استفاده شده در یک محیط چند‌مستاجره باید دنبال مجموعه‌ای دقیق‌تر از دستورالعمل‌ها باشند. به طور خاص، اپراتور باید:

- پشتیبانی از ایجاد منابع در فضاهای نام مختلف مستاجران را از جمله فضای نامی که اپراتور در آن اجرا می‌شود.
- اطمینان حاصل کنید که پادها با درخواست‌های و محدودیت‌های منابع پیکربندی شده‌اند تا برنامه‌ریزی و عدالت انجام شود.
- پشتیبانی از پیکربندی پادها برای تکنیک‌های جداسازی دیتا-پلن مانند جداسازی گره و کانتینرهای شناور داشته باشد.

## پیاده‌سازی‌ها

{{% thirdparty-content %}}

دو راه اصلی برای به اشتراک گذاری یک خوشه Kubernetes برای چند‌مستاجری وجود دارد: استفاده از فضاهای نام (یعنی، یک فضای نام برای هر مستاجر) یا با افزودن پلیر کنترل مجازی (یعنی، پلیر کنترل مجازی برای هر مستاجر).

در هر دو مورد، جداسازی دیتا-پلن و مدیریت در نظر گرفته می‌شود، همچنین معمولاً توصیه می‌شود به API اولویت و عدالت هم اضافه شود.

جداسازی فضای نام توسط Kubernetes حمایت قوی از خود را نشان می‌دهد، هزینه منابعی اندکی دارد و مکانیسم‌هایی را ارائه می‌دهد که به مستاجران امکان تعامل مناسب را می‌دهد، مانند اینکه امکان ارتباط خدمات به خدمات فعال شود. با این حال، پیکربندی آن ممکن است دشوار باشد و برای منابع Kubernetes که نمی‌توانند نام‌گذاری شوند، مانند تعریف‌های منبع سفارشی، کلاس‌های ذخیره‌سازی و وب هوک‌ها، معتبر نیست.

مجازی‌سازی پلیر کنترل اجازه جداسازی منابع بدون فضای نام را با هزینه منابع کمی بیشتر ارائه می‌دهد و بیشترین همبستگی و کمبود به اشتراک گذاشتن منابع برای حالت‌هایی که جداسازی فضای نام کافی نیست را حل می‌کند. با این حال، حتی در یک پلیر کنترل مجازی، احتمالاً بهتر است از فضاهای نام هم استفاده کنید.

در ادامه، دو گزینه به تفصیل بررسی می‌شوند.

### فضای نام

 برای هر مستاجر

همانطور که پیش‌تر اشاره شد، شما باید در نظر بگیرید که هر بارکار در یک فضای نام خود را جدا کنید، حتی اگر از خوشه‌های اختصاصی یا کنترل‌های مجازی‌سازی پلیر استفاده می‌کنید. این اطمینان می‌دهد که هر بارکار فقط به منابع خود، مانند نقشه‌های پیکربندی و رازها دسترسی دارد و به شما این امکان را می‌دهد که برای هر بارکار خود راهکارهای امنیتی اختصاصی را پیکربندی کنید. علاوه بر این، بهتر است به هر فضای نام نام‌هایی که در کلیه خودروی شما منحصر به فرد هستند (یعنی، حتی اگر آن‌ها در خوشه‌های جداگانه هستند) دهید، زیرا این امکان را به شما می‌دهد که در آینده بین خوشه‌های اختصاصی و اشتراکی جابجا شوید یا از ابزارهای چند خوشه‌ای مانند مشتی‌های خدمات استفاده کنید.

به طور مقابل، همچنین مزایای اختصاص فضاهای نام به سطح مستاجر و نه فقط سطح بارکار، وجود دارد زیرا غالباً سیاست‌هایی وجود دارد که بر همه بارکارهایی که توسط یک تنها مستاجر دارند، اعمال می‌شود. با این حال، این مسئله از مشکلات خود را پرورش می‌دهد. اولاً، این باعث می‌شود که سخت یا غیرممکن شود که سیاست‌ها را به بارکارهای فردی سفارش دهید و دوماً، ممکن است چالشی باشد که یک سطح "مستاجری" که باید یک فضای نام داده شود، پیدا شود. به عنوان مثال، یک سازمان ممکن است داشته باشد دسته‌بندی‌ها، تیم‌ها و زیرتیم‌ها - که کدام باید به یک فضای نام اختصاص داده شود؟

برای حل این مسئله، Kubernetes [کنترلر نام‌های سلسله مراتبی (HNC)](https://github.com/kubernetes-sigs/hierarchical-namespaces) را فراهم کرده است، که به شما این امکان را می‌دهد که فضاهای نام خود را به سلسله مراتب سازماندهی کنید و برخی از سیاست‌ها و منابع را بین آن‌ها به اشتراک بگذارید. این همچنین به شما کمک می‌کند که برچسب‌های فضای نام، چرخه عمر فضای نام و مدیریت اختصاص‌داده شده و به اشتراک‌گذاری سهم منابع را در فضاهای نام مرتبط به انجام برسانید. این قابلیت‌ها می‌تواند در هر دو حالت چند تیم و چند مشتری مفید باشد.

پروژه‌های دیگر که قابلیت‌های مشابهی را ارائه می‌دهند و به مدیریت منابع نام‌گذاری شده کمک می‌کنند در زیر لیست شده‌اند.

#### چند تیمی مستاجری

- [Capsule](https://github.com/clastix/capsule)
- [Kiosk](https://github.com/loft-sh/kiosk)

#### چند مشتری مستاجری

- [Kubeplus](https://github.com/cloud-ark/kubeplus)

#### موتورهای سیاست

موتورهای سیاست ویژگی‌هایی برای اعتبارسنجی و تولید پیکربندی‌های مستاجر را فراهم می‌کنند:

- [Kyverno](https://kyverno.io/)
- [OPA/Gatekeeper](https://github.com/open-policy-agent/gatekeeper)

### پلیر کنترل مجازی برای هر مستاجر

یک شکل دیگر از جداسازی پلیر کنترل استفاده از توسعه‌های Kubernetes برای ارائه یک پلیر کنترل مجازی برای هر مستاجر است که امکان تقسیم منابع API خوشه به مستاجران را فراهم می‌کند.
[تکنیک‌های جداسازی دیتا-پلن](#data-plane-isolation) می‌تواند با این مدل استفاده شود تا مدیریت امنیتی گره‌های کارگر بین مستاجران انجام شود.

مدل چند مستاجری بر پایه پلیر کنترل مجازی با ارائه کنترل پلیر مخصوص به هر مستاجر، و بنابراین کنترل کامل بر منابع خوشه و خدمات افزوده. گره‌های کارگر بین تمامی مستاجران به اشتراک گذاشته شده‌اند و توسط یک خوشه Kubernetes که به طور معمول برای مستاجران قابل دسترسی نیست مدیریت می‌شود.
این خوشه به عنوان یک _سوپر-خوشه_ (یا گاهی به عنوان _خوشه میزبان_) شناخته می‌شود.
از آنجا که پلیر کنترل یک مستاجر به صورت مستقیم به منابع محاسباتی زیرین مرتبط نیست به آن به عنوان یک _پلیر کنترل مجازی_ گفته می‌شود.

با استفاده از کنترل پلیر اختصاصی به اختلافات جداسا

زی به خاطر استفاده از یک سرور API بین تمامی مستاجران، حل شده است. به عنوان مثال همسایگی‌های نویزی در پلیر کنترل، شعاع پرتاب ناقص از اشتباهات پلیسی و تضادهای بین اشیاء چارچوبی مانند وب هوک‌ها و CRDs. بنابراین، مدل پلیر کنترل مجازی به ویژه برای مواردی که هر مستاجر به یک سرور API Kubernetes نیاز دارد و انتظار مدیریت کل خوشه را دارد، مناسب است.

جدایی بهبود یافته به قیمت اجرای و نگهداری یک پلیر کنترل اختصاصی برای هر مستاجر می‌آید. به علاوه، کنترل پلیر اختصاصی مستاجر مسائل جدایی را در دیتا-پلن، مانند همسایگی‌های نویزی در سطح گره و تهدیدهای امنیتی هنوز باید به طور جداگانه حل شوند.

پروژه [Cluster API - Nested (CAPN)](https://github.com/kubernetes-sigs/cluster-api-provider-nested/tree/main/virtualcluster) پیاده‌سازی از کنترل پلیر های مجازی را فراهم می‌کند.

#### پیاده‌سازی‌های دیگر

- [Kamaji](https://github.com/clastix/kamaji)
- [vcluster](https://github.com/loft-sh/vcluster)

