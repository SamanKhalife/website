---
reviewers:
- piosz
- x13n
title: معماری ورودی
content_type: مفهوم
weight: 60
---

<!-- مرور -->

لاگ‌های برنامه می‌توانند به شما کمک کنند تا درک بیشتری از اتفاقات داخل برنامه خود پیدا کنید.
لاگ‌ها برای رفع اشکال و نظارت بر فعالیت خوشه بسیار مفید هستند. اکثر برنامه‌های مدرن دارای
مکانیزمی برای ثبت لاگ هستند. به طور مشابه، موتورهای کانتینر به طور خاص برای پشتیبانی از ثبت
لاگ طراحی شده‌اند. روشی که آسان‌ترین و پرکاربردترین روش برای ثبت لاگ برنامه‌های کانتینری شده
است، ثبت در خروجی استاندارد و جریان خطا است.

با این حال، عملکرد اصلی ارائه شده توسط موتور یا محیط اجرای کانتینر معمولاً کافی برای یک
راه‌حل کامل ثبت لاگ نیست.

به عنوان مثال، ممکن است بخواهید به لاگ‌های برنامه‌تان دسترسی داشته باشید اگر یک کانتینر
متوقف شود، یک پاد اخراج شود یا یک نود خراب شود.

در یک خوشه، لاگ‌ها باید دارای ذخیره‌سازی و چرخه جداگانه مستقل از نودها، پادها یا
کانتینرها باشند. این مفهوم به نام
[معماری ثبت لاگ سطح خوشه](#cluster-level-logging-architectures)
شناخته می‌شود.

معماری‌های ثبت لاگ سطح خوشه نیازمند یک پشتیبان جداگانه برای ذخیره، تجزیه و تحلیل و
پرس‌وجوی لاگ‌ها هستند. Kubernetes راه‌حل ذخیره‌سازی اصلی برای داده‌های لاگ فراهم نمی‌کند.
بجای آن، بسیاری از راه‌حل‌های ثبت لاگ وجود دارند که با Kubernetes یکپارچه می‌شوند.
بخش‌های زیر توضیح می‌دهند که چگونه باید با لاگ‌ها در نودها برخورد و آن‌ها را ذخیره کنیم.

<!-- بدنه -->

## لاگ‌های پاد و کانتینر {#basic-logging-in-kubernetes}

Kubernetes لاگ‌ها را از هر کانتینر در یک پاد در حال اجرا گرفته و ذخیره می‌کند.

این مثال از یک `Pod` با یک کانتینر استفاده می‌کند که متن را به جریان خروجی استاندارد
نوشته، یک بار در هر ثانیه.

{{% code_sample file="debug/counter-pod.yaml" %}}

برای اجرای این پاد، از دستور زیر استفاده کنید:

```shell
kubectl apply -f https://k8s.io/examples/debug/counter-pod.yaml
```

خروجی این عملیات به شرح زیر است:

```console
pod/counter created
```

برای گرفتن لاگ‌ها، از دستور `kubectl logs` به شکل زیر استفاده کنید:

```shell
kubectl logs counter
```

خروجی مشابه زیر است:

```console
0: Fri Apr  1 11:42:23 UTC 2022
1: Fri Apr  1 11:42:24 UTC 2022
2: Fri Apr  1 11:42:25 UTC 2022
```

می‌توانید از `kubectl logs --previous` برای دریافت لاگ‌ها از نسخه قبلی یک کانتینر استفاده
کنید. اگر پاد شما دارای چندین کانتینر است، نام کانتینری که می‌خواهید لاگ‌های آن را
به دست آورید را با استفاده از پرچم `-c` به دستور اضافه کنید، مانند زیر:

```shell
kubectl logs counter -c count
```

برای کسب اطلاعات بیشتر، به [مستندات `kubectl logs`](/docs/reference/generated/kubectl/kubectl-commands#logs)
مراجعه کنید.

### چگونگی برخورد نودها با لاگ‌های کانتینری

![لاگ‌گذاری سطح نود](/images/docs/user-guide/logging/logging-node-level.png)

محیط اجرای کانتینر هر خروجی تولیدی را به جریان‌های `stdout` و `stderr` یک برنامه
کانتینری هدایت و تغییر می‌دهد. مختلف محیط‌های اجرای کانتینر این عمل را به شکل‌های
مختلفی پیاده‌سازی می‌کنند؛ با این حال، یکپارچگی با kubelet به عنوان _فرمت ثبت CRI_
استاندارد است.

به طور پیش‌فرض، اگر یک کانتینر دوباره راه‌اندازی شود، kubelet یک کانتینر خاتمه‌یافته با
لاگ‌های آن را نگه می‌دارد. اگر یک پاد از یک نود اخراج شود، همه کانتینرهای مربوطه همچنین
اخراج می‌شوند، به همراه لاگ‌های آن‌ها.

kubelet لاگ‌ها را از طریق یک ویژگی خاص از API Kubernetes برای مشتریان در دسترس می‌کند.
معمولاً راه معمول دسترسی به این لاگ‌ها اجرای `kubectl logs` است.

### چرخه چرخش لاگ

{{< feature-state for_k8s_version="v1.21" state="stable" >}}

kubelet مسئول چرخش لاگ کانتینر و مدیریت ساختار دایرکت

وری ثبت‌ها است.
kubelet این اطلاعات را به محیط اجرای کانتینر ارسال می‌کند (با استفاده از CRI) و
محیط اجرایی لاگ‌های کانتینر را به مکان داده شده می‌نویسد.

شما می‌توانید دو تنظیمات پیکربندی kubelet،
`containerLogMaxSize` (پیش‌فرض 10Mi) و `containerLogMaxFiles` (پیش‌فرض 5) را با استفاده
از [فایل پیکربندی kubelet](/docs/tasks/administer-cluster/kubelet-config-file/)
پیکربندی کنید. این تنظیمات به شما امکان می‌دهند حداکثر اندازه هر فایل لاگ و تعداد حداکثر
فایل‌ها را برای هر کانتینر پیکربندی کنید.

برای انجام چرخه چرخش کارآمد در خوشه‌هایی که حجم لاگ‌های تولیدی توسط بار کاری زیاد است،
kubelet همچنین مکانیسمی را برای تنظیم چگونگی چرخش لاگ‌ها ارائه می‌دهد، که شامل تعداد چرخش
همزمان لاگ‌ها و فاصله زمانی است که لاگ‌ها به همراه نظارت و به همراه نیاز مدار کنترل می‌کند.
شما می‌توانید دو تنظیمات پیکربندی kubelet،
`containerLogMaxWorkers` و `containerLogMonitorInterval` را با استفاده از
[فایل پیکربندی kubelet](/docs/tasks/administer-cluster/kubelet-config-file/)
پیکربندی کنید.

زمانی که شما همچنان [`kubectl logs`](/docs/reference/generated/kubectl/kubectl-commands#logs)
را مانند مثال پایه‌ای ثبت لاگ اجرا می‌کنید، kubelet روی نود درخواست را
پردازش کرده و مستقیماً از فایل لاگ خوانده می‌شود. kubelet محتوای فایل لاگ را برمی‌گرداند.

{{< note >}}
تنها محتوای آخرین فایل لاگ از طریق `kubectl logs` در دسترس است.

به عنوان مثال، اگر یک پاد 40 MiB لاگ را نوشته باشد و kubelet پس از 10 MiB لاگ‌ها را
چرخاند، اجرای `kubectl logs` حداکثر 10MiB از داده را برمی‌گرداند.
{{< /note >}}
## لاگ‌های مؤلفه‌های سیستمی

در سیستم‌های کنترل کننده‌ای دو نوع مؤلفه وجود دارد: آن‌هایی که معمولاً در یک کانتینر اجرا می‌شوند و آن‌هایی که مستقیماً در اجرای کانتینرها دخیل هستند. به عنوان مثال:

- kubelet و container runtime در کانتینرها اجرا نمی‌شوند. kubelet کانتینرهای شما را (که در گروه‌هایی به نام {{< glossary_tooltip text="pods" term_id="pod" >}} قرار دارند) اجرا می‌کند.
- زمان برنامه‌نویس، کنترل کننده اجرا، و سرور API Kubernetes درون pods اجرا می‌شوند (معمولاً {{< glossary_tooltip text="static Pods" term_id="static-pod" >}}). مؤلفه etcd در زمینه کنترل، و به صورت متداول همچنین به عنوان یک static pod اجرا می‌شود. اگر خوشه شما از kube-proxy استفاده می‌کند، معمولاً آن را به عنوان یک `DaemonSet` اجرا می‌کنید.

### مکان‌های لاگ {#log-location-node}

نحوه نوشتن kubelet و container runtime به لاگ‌ها، بستگی به سیستم‌عاملی دارد که گره از آن استفاده می‌کند:

{{< tabs name="log_location_node_tabs" >}}
{{% tab name="Linux" %}}

در گره‌های لینوکسی که از systemd استفاده می‌کنند، kubelet و container runtime به طور پیش‌فرض به journald می‌نویسند. برای مثال از `journalctl` برای خواندن ژورنال systemd استفاده می‌شود؛ به عنوان مثال: `journalctl -u kubelet`.

اگر systemd موجود نباشد، kubelet و container runtime به فایل‌های `.log` در دایرکتوری `/var/log` می‌نویسند. اگر می‌خواهید لاگ‌ها را در جای دیگری نوشته شود، می‌توانید به طور غیرمستقیم kubelet را از طریق ابزار کمکی به نام `kube-log-runner` اجرا کرده و از این ابزار برای تغییر مسیر نوشتن لاگ‌های kubelet به یک دایرکتوری دلخواه استفاده کنید.

به طور پیش‌فرض، kubelet دستور container runtime شما را برای نوشتن لاگ‌ها به داخل دایرکتوری‌های درون `/var/log/pods` هدایت می‌کند.

برای اطلاعات بیشتر درباره `kube-log-runner`، به مطالب [لاگ‌های سیستمی](/docs/concepts/cluster-administration/system-logs/#klog) مراجعه کنید.

{{% /tab %}}
{{% tab name="Windows" %}}

به طور پیش‌فرض، kubelet لاگ‌ها را به فایل‌ها در داخل دایرکتوری `C:\var\logs` می‌نویسد (توجه کنید که این با `C:\var\log` متفاوت است).

اگرچه `C:\var\log` مکان پیش‌فرض Kubernetes برای این لاگ‌هاست، اما چندین ابزار نصب شده بر روی گره‌های Windows برای ثبت لاگ‌ها به `C:\var\log\kubelet` هدایت می‌شوند.

اگر می‌خواهید لاگ‌ها را در مکان دیگری نوشته شود، می‌توانید به طور غیرمستقیم kubelet را از طریق ابزار کمکی به نام `kube-log-runner` اجرا کرده و از این ابزار برای تغییر مسیر نوشتن لاگ‌های kubelet به یک دایرکتوری دلخواه استفاده کنید.

به طور پیش‌فرض، kubelet دستور container runtime شما را برای نوشتن لاگ‌ها داخل دایرکتوری `C:\var\log\pods` هدایت می‌کند.

برای اطلاعات بیشتر درباره `kube-log-runner`، به مطالب [لاگ‌های سیستمی](/docs/concepts/cluster-administration/system-logs/#klog) مراجعه کنید.

{{% /tab %}}
{{< /tabs >}}

<br /><!-- راه حل‌های پیشنهادی برای اجرای نیت -->

برای مؤلفه‌های خوشه Kubernetes که در pods اجرا می‌شوند، این‌ها به فایل‌های درون دایرکتوری `/var/log` می‌نویسند و از مکانیزم پیش‌فرض لاگ (مؤلفه‌ها به ژورنال systemd نمی‌نویسند) استفاده می‌کنند Kubernetes. می‌توانید از مکانیزم‌های ذخیره‌سازی Kubernetes استفاده کنید تا ذخیره‌سازی مستدام را در کانتینری که مؤلفه را اجرا می‌کند، نقشه‌برداری کنید.

kubelet امکان تغییر دایرکتوری لاگ پادها را از مسیر پیش‌فرض `/var/log/pods` به یک مسیر دلخواه فراهم می‌کند. این تنظیم می‌تواند با تنظیم پارامتر `podLogsDir` در فایل پیکربندی kubelet انجام شود.

{{< caution >}}
مهم است که توجه داشته باشید که مسیر پیش‌فرض `/var/log/pods` برای یک مدت طولانی استفاده می‌شود و برخی فرایندها ممکن است به طور ضمنی به این مسیر اشاره کنند. بنابراین، تغییر این پارامتر باید با احتیاط و به عهده خود شما باشد.

یک ملاحظه دیگر این است که kubelet پشتیبانی از مکانیزم استفاده می‌کند که مسیر باید در

 همان دیسکی که `/var` است بود. در غیر این صورت، اگر لاگ‌ها در یک فایل سیستم جداگانه از `/var` باشند، kubelet به پیگیری استفاده از این فایل‌سیستم پرداخته نمی‌شود که ممکن است به مشکلاتی منجر شود اگر این فایل‌سیستم پر شود.

{{< /caution >}}

برای جزییات درباره etcd و لاگ‌های آن، به [مستندات etcd](https://etcd.io/docs/) مراجعه کنید. همچنین، می‌توانید از مکانیزم‌های ذخیره‌سازی Kubernetes برای نقشه‌برداری ذخیره‌سازی مستدام به کانتینری که مؤلفه را اجرا می‌کند، استفاده کنید.

{{< note >}}
اگر مؤلفه‌های خوشه Kubernetes (مانند اجرای scheduler) را برای ثبت لاگ به یک حجم اشتراکی از گره والد اجرا کنید، باید از آن اطمینان حاصل کنید که این لاگ‌ها چرخه زمانی را دارند و اطمینان حاصل کنید که این لاگ‌ها چرخه‌ها را انجام می‌دهند. **Kubernetes مدیریت این چرخه‌ها را انجام نمی‌دهد**.

سیستم‌عامل شما ممکن است به صورت خودکار برخی از چرخه‌های زمانی را اجرا کند - به عنوان مثال، اگر شما فهرست `/var/log` را به یک پاد استاتیک برای یک مؤلفه به اشتراک بگذارید، چرخه‌زمانی لاگ فایل را با یک فایلی که توسط هر مؤلفه خارج از Kubernetes نوشته شده، مدیریت می‌کند.

برخی ابزارهای نصب و راه‌اندازی این چرخه‌ها را مدیریت کرده و خودکار کرده‌اند؛ بقیه این مسئولیت را بر عهده خودتان می‌گذارند.
{{< /note >}}

## معماری لاگ‌گیری در سطح خوشه

اگرچه Kubernetes راه‌حلی نیتیو برای لاگ‌گیری در سطح خوشه فراهم نمی‌کند، چندین رویکرد متداولی وجود دارد که می‌توانید در نظر بگیرید. در ادامه چندین گزینه وجود دارد:

- استفاده از یک عامل لاگ‌گیری سطح گره که بر روی هر گره اجرا می‌شود.
- اضافه کردن یک کانتینر کناری اختصاصی برای لاگ‌گیری در یک پاد برنامه.
- پوش کردن لاگ‌ها مستقیماً به یک زیرساخت از داخل یک برنامه.

### استفاده از یک عامل لاگ‌گیری گره

![استفاده از یک عامل لاگ‌گیری سطح گره](/images/docs/user-guide/logging/logging-with-node-agent.png)

شما می‌توانید با اضافه کردن یک _عامل لاگ‌گیری سطح گره_ بر روی هر گره، لاگ‌گیری سطح خوشه را پیاده‌سازی کنید. عامل لاگ‌گیری یک ابزار اختصاصی است که لاگ‌ها را نمایش می‌دهد یا آن‌ها را به یک زیرساخت ارسال می‌کند. به طور معمول، عامل لاگ‌گیری یک کانتینر است که دسترسی به یک دایرکتوری با فایل‌های لاگ از تمام کانتینرهای برنامه در آن گره دارد.

زیرا عامل لاگ‌گیری باید بر روی هر گره اجرا شود، توصیه می‌شود که عامل را به عنوان یک `DaemonSet` اجرا کنید.

لاگ‌گیری سطح گره فقط یک عامل برای هر گره ایجاد می‌کند و نیازی به هیچ تغییری در برنامه‌های در حال اجرا بر روی گره نیست.

کانتینرها به stdout و stderr می‌نویسند، اما با فرمت متفاوت. یک عامل سطح گره این لاگ‌ها را جمع‌آوری کرده و آن‌ها را به منظور تجمیع ارسال می‌کند.
### استفاده از کانتینر کناری با عامل لاگ‌گیری

شما می‌توانید از یک کانتینر کناری به یکی از روش‌های زیر استفاده کنید:

- **کانتینر کناری جریان‌دهنده**:
  
  ![کانتینر کناری با کانتینر جریان‌دهنده](/images/docs/user-guide/logging/logging-with-streaming-sidecar.png)
  
  با این رویکرد، کانتینر کناری خود را به `stdout` و `stderr` خود می‌نویسد و از kubelet و عامل لاگ‌گیری که هر گره اجرا می‌شود بهره می‌برد. کانتینرهای کناری لاگ‌ها را از یک فایل، سوکت یا journald خوانده و به `stdout` یا `stderr` خود چاپ می‌کنند.

  این رویکرد به شما اجازه می‌دهد تا چندین جریان لاگ را از بخش‌های مختلف برنامه خود جدا کنید، برخی از آن‌ها که پشتیبانی کافی برای نوشتن به `stdout` یا `stderr` ندارند. منطق پشت راهنمایی لاگ‌ها حداقل است، بنابراین این مسئله یک هدردرد مهم نیست. به علاوه، با توجه به این که `stdout` و `stderr` توسط kubelet اداره می‌شوند، می‌توانید از ابزارهای داخلی مانند `kubectl logs` استفاده کنید.

  به عنوان مثال، یک pod یک کانتینر واحد را اجرا می‌کند و کانتینر فایل‌های لاگ را با دو فرمت متفاوت می‌نویسد. در ادامه، یک مانیفست برای Pod نشان داده می‌شود:

  ```yaml
  {{% code_sample file="admin/logging/two-files-counter-pod.yaml" %}}
  ```

  توصیه نمی‌شود که موارد مختلفی را با فرمت‌های مختلف به یک جریان لاگ مشترک، حتی اگر بتوانید هر دو متن را به `stdout` یک کانتینر انتقال دهید، نوشته شود. به جای این کار، می‌توانید دو کانتینر کناری ایجاد کنید. هر کانتینر کناری می‌تواند یک فایل لاگ خاص را از یک واحد به اشتراک بگذارد و سپس لاگ‌ها را به `stdout` خود انتقال دهد.

  مانیفستی برای یک pod با دو کانتینر کناری به شرح زیر است:

  ```yaml
  {{% code_sample file="admin/logging/two-files-counter-pod-streaming-sidecar.yaml" %}}
  ```

  حالا هنگام اجرای این pod، می‌توانید به هر جریان لاگ به طور جداگانه دسترسی پیدا کنید با اجرای دستورات زیر:

  ```shell
  kubectl logs counter count-log-1
  ```

  خروجی مشابه زیر است:

  ```console
  0: Fri Apr  1 11:42:26 UTC 2022
  1: Fri Apr  1 11:42:27 UTC 2022
  2: Fri Apr  1 11:42:28 UTC 2022
  ...
  ```

  ```shell
  kubectl logs counter count-log-2
  ```

  خروجی مشابه زیر است:

  ```console
  Fri Apr  1 11:42:29 UTC 2022 INFO 0
  Fri Apr  1 11:42:30 UTC 2022 INFO 0
  Fri Apr  1 11:42:31 UTC 2022 INFO 0
  ...
  ```

  اگر در خوشه خود عامل سطح گره‌ای نصب کردید، این عامل به طور خودکار جریان‌های لاگ را بدون نیاز به پیکربندی بیشتری از شما برمی‌گرداند. اگر بخواهید، می‌توانید عامل را به گونه‌ای پیکربندی کنید که خطوط لاگ را براساس منبع کانتینر انتخاب کند.

- **کانتینر کناری با یک عامل لاگ‌گیری**:

  ![کانتینر کناری با یک عامل لاگ‌گیری](/images/docs/user-guide/logging/logging-with-sidecar-agent.png)

  اگر عامل لاگ‌گیری سطح گره برای شرایط خاص شما کافی نباشد، می‌توانید یک کانتینر کناری با یک عامل لاگ‌گیری جداگانه ایجاد کنید که به طور خاص برای برنامه شما پیکربندی شده است.

  {{< note >}}
  استفاده از یک عامل لاگ‌گیری در یک کانتینر کناری می‌تواند منجر به مصرف منابع قابل توجهی شود. علاوه بر این، شما قادر به دسترسی به این لاگ‌ها با استفاده از `kubectl logs` نیستید چرا که توسط kubelet کنترل نمی‌شود.
  {{< /note >}}

  در ادامه دو مانیفست نمونه وجود دارد که می‌توانید برای پیاده‌سازی یک کانتینر کناری با یک عامل لاگ‌گیری استفاده کنید. مانیفست اول شامل یک [`ConfigMap`](/docs/tasks/configure-pod-container/configure-pod-configmap/) برای پیکربندی fluentd است.

  ```yaml
  {{% code_sample file="admin/logging/fluentd-sidecar-config.yaml" %}}
  ```

  {{< note >}}
  در پیکربندی‌های نمونه، می‌توانید fluentd را با هر عامل لاگ‌گیری دیگری که از هر منبع داخل یک کانتینر برنامه خواندن استفاده کنید.
  {{< /note >}}

  مانیفست دوم توصیف می‌کند که یک pod دارای یک کانتینر کناری است که fluentd را اجرا می‌کند. این pod یک حجم را نص

ب می‌کند که fluentd می‌تواند داده‌های پیکربندی خود را بردارد.

  ```yaml
  {{% code_sample file="admin/logging/two-files-counter-pod-agent-sidecar.yaml" %}}
  ```

### افشای لاگ‌ها مستقیماً از برنامه

![افشای لاگ‌ها مستقیماً از برنامه](/images/docs/user-guide/logging/logging-from-application.png)

لاگ‌گیری خوشه‌ای که لاگ‌ها را مستقیماً از هر برنامه افشا یا پیش می‌کند، خارج از دامنه Kubernetes است.

## {{% heading "whatsnext" %}}

* درباره [لاگ‌های سیستم Kubernetes](/docs/concepts/cluster-administration/system-logs/) بیشتر بخوانید.
* درباره [ردیابی‌ها برای اجزای سیستم Kubernetes](/docs/concepts/cluster-administration/system-traces/) بیشتر بخوانید.
* یاد بگیرید چگونه [پیام‌های پایانی را سفارشی کنید](/docs/tasks/debug/debug-application/determine-reason-pod-failure/#customizing-the-termination-message) که Kubernetes آن‌ها را ضبط می‌کند هنگامی که یک Pod ناکام می‌شود.