---
reviewers:
- davidopp
- lavalamp
title: ملاحظات برای کلاسترهای بزرگ
weight: 10
---

یک کلاستر مجموعه‌ای از {{< glossary_tooltip text="گره‌ها" term_id="node" >}} (ماشین‌های فیزیکی یا مجازی) است که عامل‌های Kubernetes را اجرا می‌کنند و توسط
{{< glossary_tooltip text="صفحه کنترل" term_id="control-plane" >}} مدیریت می‌شوند.
Kubernetes {{< param "version" >}} از کلاسترهایی با حداکثر ۵۰۰۰ گره پشتیبانی می‌کند. به طور خاص، Kubernetes به گونه‌ای طراحی شده که پیکربندی‌هایی که *همه* معیارهای زیر را برآورده می‌کنند را پشتیبانی کند:

* حداکثر ۱۱۰ پاد در هر گره
* حداکثر ۵۰۰۰ گره
* حداکثر ۱۵۰,۰۰۰ پاد کل
* حداکثر ۳۰۰,۰۰۰ کانتینر کل

شما می‌توانید کلاستر خود را با افزودن یا حذف گره‌ها مقیاس کنید. نحوه انجام این کار بستگی به نحوه استقرار کلاستر شما دارد.

## سهمیه منابع ارائه‌دهنده‌ی ابری {#quota-issues}

برای جلوگیری از مواجهه با مشکلات سهمیه ارائه‌دهنده‌ی ابری، هنگام ایجاد کلاستر با تعداد زیادی گره، موارد زیر را در نظر بگیرید:
* درخواست افزایش سهمیه برای منابع ابری مانند:
    * نمونه‌های کامپیوتری
    * CPU ها
    * حجم‌های ذخیره‌سازی
    * آدرس‌های IP در استفاده
    * مجموعه قوانین فیلتر کردن بسته‌ها
    * تعداد بالانسرهای بار
    * زیرشبکه‌های شبکه
    * جریان‌های لاگ
* محدود کردن اقدامات مقیاس‌بندی کلاستر برای ایجاد گره‌های جدید به صورت دسته‌ای، با یک وقفه
  بین دسته‌ها، زیرا برخی ارائه‌دهندگان ابری سرعت ایجاد نمونه‌های جدید را محدود می‌کنند.

## اجزای صفحه کنترل

برای یک کلاستر بزرگ، شما نیاز به صفحه کنترل با منابع محاسباتی و سایر منابع کافی دارید.

معمولاً شما یک یا دو نمونه صفحه کنترل در هر منطقه خرابی اجرا می‌کنید،
این نمونه‌ها را ابتدا به صورت عمودی مقیاس کرده و سپس بعد از رسیدن به نقطه بازده نزولی، به صورت افقی مقیاس می‌دهید.

شما باید حداقل یک نمونه در هر منطقه خرابی برای ارائه‌ی تحمل خطا اجرا کنید. گره‌های Kubernetes به طور خودکار ترافیک را به سمت نقاط انتهایی صفحه کنترل که در همان منطقه خرابی هستند هدایت نمی‌کنند؛ با این حال، ممکن است ارائه‌دهنده‌ی ابری شما مکانیسم‌های خود را برای انجام این کار داشته باشد.

برای مثال، با استفاده از یک بالانسر بار مدیریت شده، می‌توانید بالانسر بار را پیکربندی کنید تا ترافیکی که از kubelet و Pods در منطقه خرابی _A_ منشاء می‌گیرد را تنها به میزبان‌های صفحه کنترل که در همان منطقه _A_ هستند هدایت کند. اگر یک میزبان صفحه کنترل یا نقطه انتهایی در منطقه _A_ آفلاین شود، به این معنی است که تمام ترافیک صفحه کنترل برای گره‌های منطقه _A_ اکنون بین مناطق ارسال می‌شود. اجرای چندین میزبان صفحه کنترل در هر منطقه، این نتیجه را کمتر محتمل می‌کند.

### ذخیره‌سازی etcd

برای بهبود عملکرد کلاسترهای بزرگ، می‌توانید اشیاء Event را در یک نمونه etcd جداگانه و اختصاصی ذخیره کنید.

هنگام ایجاد یک کلاستر، می‌توانید (با استفاده از ابزارهای سفارشی):

* نمونه‌ی اضافی etcd را راه‌اندازی و پیکربندی کنید
* {{< glossary_tooltip term_id="kube-apiserver" text="سرور API" >}} را پیکربندی کنید تا برای ذخیره‌سازی رویدادها از آن استفاده کند

جزئیات مربوط به پیکربندی و مدیریت etcd برای یک کلاستر بزرگ را در [مدیریت کلاسترهای etcd برای Kubernetes](/docs/tasks/administer-cluster/configure-upgrade-etcd/) و
[راه‌اندازی یک کلاستر etcd با دسترسی بالا با kubeadm](/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/) ببینید.

## منابع افزودنی

[محدودیت‌های منابع](/docs/concepts/configuration/manage-resources-containers/) Kubernetes به کاهش تاثیر نشت‌های حافظه و دیگر راه‌هایی که پادها و کانتینرها می‌توانند بر روی اجزای دیگر تاثیر بگذارند کمک می‌کنند. این محدودیت‌های منابع به
{{< glossary_tooltip text="افزونه" term_id="addons" >}} ها همانطور که به بارهای کاری کاربردی اعمال می‌شوند اعمال می‌شوند.

برای مثال، می‌توانید محدودیت‌های CPU و حافظه را برای یک جزء لاگ تنظیم کنید:

```yaml
  ...
  containers:
  - name: fluentd-cloud-logging
    image: fluent/fluentd-kubernetes-daemonset:v1
    resources:
      limits:
        cpu: 100m
        memory: 200Mi
```

محدودیت‌های پیش‌فرض افزودنی‌ها معمولاً بر اساس داده‌های جمع‌آوری شده از تجربه اجرای هر افزودنی در کلاسترهای کوچک یا متوسط است. هنگام اجرا در کلاسترهای بزرگ، افزودنی‌ها اغلب منابع بیشتری از محدودیت‌های پیش‌فرض خود مصرف می‌کنند.
اگر یک کلاستر بزرگ بدون تنظیم این مقادیر مستقر شود، افزودنی(ها) ممکن است به طور مداوم به دلیل رسیدن به محدودیت حافظه کشته شوند. به طور متناوب، افزودنی ممکن است اجرا شود اما با عملکرد ضعیف به دلیل محدودیت‌های زمان CPU.

برای جلوگیری از مواجهه با مشکلات منابع افزودنی کلاستر، هنگام ایجاد یک کلاستر با
تعداد زیادی گره، موارد زیر را در نظر بگیرید:

* برخی افزودنی‌ها به صورت عمودی مقیاس می‌شوند - یک نسخه از افزودنی برای کلاستر
  یا خدمت‌دهی به یک منطقه خرابی. برای این افزودنی‌ها، درخواست‌ها و محدودیت‌ها را
  افزایش دهید وقتی کلاستر خود را مقیاس می‌دهید.
* بسیاری از افزودنی‌ها به صورت افقی مقیاس می‌شوند - شما با اجرای پادهای بیشتر ظرفیت را اضافه می‌کنید - اما با
  یک کلاستر بسیار بزرگ ممکن است نیاز به افزایش محدودیت‌های CPU یا حافظه داشته باشید.
  VerticalPodAutoscaler می‌تواند در حالت _توصیه‌کننده_ اجرا شود تا ارقام پیشنهادی برای درخواست‌ها و محدودیت‌ها را ارائه دهد.
* برخی افزودنی‌ها به عنوان یک نسخه در هر گره اجرا می‌شوند که توسط {{< glossary_tooltip text="DaemonSet"
  term_id="daemonset" >}} کنترل می‌شوند: برای مثال، یک جمع‌آوری کننده‌ی لاگ در سطح گره. مشابه
  حالت افزودنی‌های مقیاس شده به صورت افقی، ممکن است نیاز به افزایش محدودیت‌های CPU یا حافظه داشته باشید.

## {{% heading "whatsnext" %}}

* `VerticalPodAutoscaler` یک منبع سفارشی است که می‌توانید در کلاستر خود مستقر کنید
برای کمک به مدیریت درخواست‌ها و محدودیت‌های منابع برای پادها.
بیشتر در مورد [Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme)
و چگونگی استفاده از آن برای مقیاس کردن اجزای کلاستر
از جمله افزودنی‌های حیاتی کلاستر یاد بگیرید.

* درباره‌ی [مقیاس‌بندی خودکار کلاستر](/docs/concepts/cluster-administration/cluster-autoscaling/) بخوانید.

* [افزونه‌ی تغییر اندازه‌دهنده](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer#readme)
به شما کمک می‌کند تا افزودنی‌ها را به صورت خودکار با تغییر مقیاس کلاستر تغییر اندازه دهید.
